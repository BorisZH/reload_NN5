{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqlu5t0nvZHHZRsPx/icEz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"in0PyicHhZDG","executionInfo":{"status":"ok","timestamp":1668449235033,"user_tz":-180,"elapsed":1979,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"outputs":[],"source":["import datetime\n","\n","from google.colab import drive\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"73ieMA485Tme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668449255370,"user_tz":-180,"elapsed":20342,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"fd97de16-20b8-4d09-99da-e6a3433ae1dd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_dir = 'drive/My Drive/'\n","train_lang = 'en'"],"metadata":{"id":"Os4tVkvmkTIp","executionInfo":{"status":"ok","timestamp":1668449255371,"user_tz":-180,"elapsed":6,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class DatasetSeq(Dataset):\n","    def __init__(self, data_dir, train_lang='en'):\n","\t#open file\n","        with open(data_dir + train_lang + '.train', 'r') as f:\n","            train = f.read().split('\\n\\n')\n","\n","        # delete extra tag markup\n","        train = [x for x in train if not '_ ' in x]\n","\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n","        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n","        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n","        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n","\t    \n","        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n","        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n","        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n","\n","\t    #init encoded sequences lists (processed data)\n","        self.encoded_sequences = []\n","        self.encoded_targets = []\n","        self.encoded_char_sequences = []\n","        # n=1 because first value is padding\n","        n_word = 1\n","        n_target = 1\n","        n_char = 1\n","        for line in train:\n","            sequence = []\n","            target = []\n","            chars = []\n","            for item in line.split('\\n'):\n","                if item != '':\n","                    word, label = item.split(' ')\n","\n","                    if self.word_vocab.get(word) is None:\n","                        self.word_vocab[word] = n_word\n","                        n_word += 1\n","                    if self.target_vocab.get(label) is None:\n","                        self.target_vocab[label] = n_target\n","                        n_target += 1\n","                    for char in word:\n","                        if self.char_vocab.get(char) is None:\n","                            self.char_vocab[char] = n_char\n","                            n_char += 1\n","                    sequence.append(self.word_vocab[word])\n","                    target.append(self.target_vocab[label])\n","                    chars.append([self.char_vocab[char] for char in word])\n","            self.encoded_sequences.append(sequence)\n","            self.encoded_targets.append(target)\n","            self.encoded_char_sequences.append(chars)\n","\n","    def __len__(self):\n","        return len(self.encoded_sequences)\n","\n","    def __getitem__(self, index):\n","        return {\n","            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n","            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n","            'target': self.encoded_targets[index], #  (1)\n","        }"],"metadata":{"id":"SI8UCZuy7hTK","executionInfo":{"status":"ok","timestamp":1668449256804,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset = DatasetSeq(data_dir)"],"metadata":{"id":"dhJuBtoz7f43","executionInfo":{"status":"ok","timestamp":1668449258924,"user_tz":-180,"elapsed":1817,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#padding\n","# seq1 = [1, 2, 3, 4]\n","# seq2 = [9, 7, 6, 4, 3, 7, 5]\n","# pad seq1 equal seq2\n","# seq1 = [1, 2, 3, 4, 0, 0, 0]\n","# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n","#                     [9, 7, 6, 4, 3, 7, 5]]"],"metadata":{"id":"0zXXXYP37gFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(input_data):\n","    data = []\n","    chars = []\n","    targets = []\n","    max_len = 0\n","    for item in input_data:\n","        if len(item['data']) > max_len:\n","            max_len = len(item['data'])\n","        data.append(torch.as_tensor(item['data']))\n","        chars.append(item['char'])\n","        targets.append(torch.as_tensor(item['target']))\n","    chars_seq = [[torch.as_tensor([0]) for _ in range(len(input_data))] for _ in range(max_len)]\n","    for j in range(len(input_data)):\n","        for i in range(max_len):\n","            if len(chars[j]) > i:\n","                chars_seq[i][j] = torch.as_tensor(chars[j][i])\n","    for j in range(max_len):\n","        chars_seq[j] = pad_sequence(chars_seq[j], batch_first=True, padding_value=0)\n","    data = pad_sequence(data, batch_first=True, padding_value=0)\n","    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n","    return {\n","        'data': data, # B x T\n","        'chars': chars_seq, # List[tensor];   tensor B x word_len; len(chars_seq) = n_words =  T\n","        'target': targets}"],"metadata":{"id":"uPJauY4hAqJ6","executionInfo":{"status":"ok","timestamp":1668449261657,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class CharRNN(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, x):\n","        emb = self.char_emb(x)\n","        _, out = self.rnn(emb) # 1 x B x Hid\n","\n","        return out.squeeze().unsqueeze(1) # B x 1 x Hid"],"metadata":{"id":"KTz2txO4LTZ3","executionInfo":{"status":"ok","timestamp":1668449273984,"user_tz":-180,"elapsed":4,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class RNNPredictorV2(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, \n","                 char_vocab, char_emb, char_hidden):\n","        super().__init__()\n","        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n","        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n","        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n","        self.rnn = nn.GRU(emb_dim + char_hidden, hidden_dim, batch_first=True)\n","        self.clf = nn.Linear(hidden_dim, n_classes)\n","        self.do = nn.Dropout(0.1)\n","        self.char_rnn = CharRNN(char_vocab, char_emb, char_hidden)\n","    \n","    def forward(self, x, chars):\n","        emb = self.word_emb(x) # B x T x Emb_dim\n","        char_feat = [self.char_rnn(c.to(x.device)) for c in chars] \n","        char_feat = torch.cat(char_feat, dim=1) # B x T x Hid_char\n","        emb = torch.cat((emb, char_feat), dim=-1)\n","        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n","        pred = self.clf(self.do(hidden)) # B x T x N_classes\n","\n","        return pred"],"metadata":{"id":"WBFZc1qY6HsC","executionInfo":{"status":"ok","timestamp":1668449275076,"user_tz":-180,"elapsed":1,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#hyper params\n","vocab_size = len(dataset.word_vocab) + 1\n","n_classes = len(dataset.target_vocab) + 1\n","n_chars = len(dataset.char_vocab) + 1\n","#TODO try to use other model parameters\n","emb_dim = 256\n","hidden = 256\n","char_hid = 64\n","char_emb = 32\n","n_epochs = 10\n","batch_size = 64\n","cuda_device = 0\n","batch_size = 100\n","device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"],"metadata":{"id":"K_PACmDaH8Z7","executionInfo":{"status":"ok","timestamp":1668449287580,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = RNNPredictorV2(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n","model.train()\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()"],"metadata":{"id":"a4gX5zVDIZdu","executionInfo":{"status":"ok","timestamp":1668449298146,"user_tz":-180,"elapsed":8255,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jVX0P0otIk4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for epoch in range(n_epochs):\n","    dataloader = DataLoader(dataset, \n","                            batch_size, \n","                            shuffle=True, \n","                            collate_fn=collate_fn,\n","                            drop_last = True,\n","                            )\n","    for i, batch in enumerate(dataloader):\n","        optim.zero_grad()\n","\n","        predict = model(batch['data'].to(device), batch['chars'])\n","        loss = loss_func(predict.view(-1, n_classes),\n","                         batch['target'].to(device).view(-1), \n","                         )\n","        loss.backward()\n","        optim.step()\n","        if i % 100 == 0:\n","            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n","   \n","    torch.save(model.state_dict(), f'./rnn_chkpt_{epoch}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2f3MATJ8GKb","executionInfo":{"status":"ok","timestamp":1668449544830,"user_tz":-180,"elapsed":241947,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"45f5cc59-35fb-4c39-91c1-aaef210da3aa"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0, step: 0, loss: 2.804795980453491\n","epoch: 0, step: 100, loss: 0.2279670685529709\n","epoch: 0, step: 200, loss: 0.21285483241081238\n","epoch: 1, step: 0, loss: 0.13917115330696106\n","epoch: 1, step: 100, loss: 0.12040182203054428\n","epoch: 1, step: 200, loss: 0.08962088078260422\n","epoch: 2, step: 0, loss: 0.05651814490556717\n","epoch: 2, step: 100, loss: 0.06905965507030487\n","epoch: 2, step: 200, loss: 0.06945423781871796\n","epoch: 3, step: 0, loss: 0.05929999426007271\n","epoch: 3, step: 100, loss: 0.06936029344797134\n","epoch: 3, step: 200, loss: 0.042604923248291016\n","epoch: 4, step: 0, loss: 0.06931573152542114\n","epoch: 4, step: 100, loss: 0.055698905140161514\n","epoch: 4, step: 200, loss: 0.05163402482867241\n","epoch: 5, step: 0, loss: 0.03924825042486191\n","epoch: 5, step: 100, loss: 0.046416640281677246\n","epoch: 5, step: 200, loss: 0.04872972518205643\n","epoch: 6, step: 0, loss: 0.038787733763456345\n","epoch: 6, step: 100, loss: 0.035300564020872116\n","epoch: 6, step: 200, loss: 0.03429068624973297\n","epoch: 7, step: 0, loss: 0.03152992203831673\n","epoch: 7, step: 100, loss: 0.05394963547587395\n","epoch: 7, step: 200, loss: 0.033172134310007095\n","epoch: 8, step: 0, loss: 0.036864783614873886\n","epoch: 8, step: 100, loss: 0.025215743109583855\n","epoch: 8, step: 200, loss: 0.021019799634814262\n","epoch: 9, step: 0, loss: 0.018039004877209663\n","epoch: 9, step: 100, loss: 0.029551485553383827\n","epoch: 9, step: 200, loss: 0.025685401633381844\n"]}]},{"cell_type":"code","source":["#example\n","#TODO modify inference for model with char input\n","phrase = 'He ran quickly after the red bus and caught it'\n","words = phrase.split(' ')\n","tokens = [dataset.word_vocab[w] for w in words]\n","\n","start = datetime.datetime.now()\n","with torch.no_grad():\n","    model.eval()\n","    predict = model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n","    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n","    end = datetime.datetime.now() - start\n","\n","target_labels = list(dataset.target_vocab.keys())\n","print([target_labels[l-1] for l in labels])"],"metadata":{"id":"9CljFAzIMMEW","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1668449560059,"user_tz":-180,"elapsed":523,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"7a99b88e-4d48-41c9-f133-d569ae0f451d"},"execution_count":12,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-04c3caca31ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 x T x N_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'chars'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"soes4kIU8FDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9PbgCjN48FRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"74gggSX58Fe9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-57Jq-CW8NmD"}}]}