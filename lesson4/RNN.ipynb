{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNk9sBWMHKlS2RdNBCHahV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"in0PyicHhZDG","executionInfo":{"status":"ok","timestamp":1668446584511,"user_tz":-180,"elapsed":1768,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"outputs":[],"source":["import datetime\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"73ieMA485Tme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668446616465,"user_tz":-180,"elapsed":31959,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"ab77bc91-b158-48d8-fe70-db0f049e17b6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_dir = 'drive/My Drive/'\n","train_lang = 'en'"],"metadata":{"id":"Os4tVkvmkTIp","executionInfo":{"status":"ok","timestamp":1668446767084,"user_tz":-180,"elapsed":585,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class DatasetSeq(Dataset):\n","    def __init__(self, data_dir, train_lang='en'):\n","\t#open file\n","        with open(data_dir + train_lang + '.train', 'r') as f:\n","            train = f.read().split('\\n\\n')\n","\n","        # delete extra tag markup\n","        train = [x for x in train if not '_ ' in x]\n","\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n","        self.target_vocab = {'<pad>': 0} # {p: 1, a: 2, r: 3, pu: 4}\n","        self.word_vocab = {'<pad>': 0} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n","        self.char_vocab = {'<pad>': 0} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n","\t    \n","        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n","        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n","        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n","\n","\t    #init encoded sequences lists (processed data)\n","        self.encoded_sequences = []\n","        self.encoded_targets = []\n","        self.encoded_char_sequences = []\n","        # n=1 because first value is padding\n","        n_word = 1\n","        n_target = 1\n","        n_char = 1\n","        for line in train:\n","            sequence = []\n","            target = []\n","            chars = []\n","            for item in line.split('\\n'):\n","                if item != '':\n","                    word, label = item.split(' ')\n","\n","                    if self.word_vocab.get(word) is None:\n","                        self.word_vocab[word] = n_word\n","                        n_word += 1\n","                    if self.target_vocab.get(label) is None:\n","                        self.target_vocab[label] = n_target\n","                        n_target += 1\n","                    for char in word:\n","                        if self.char_vocab.get(char) is None:\n","                            self.char_vocab[char] = n_char\n","                            n_char += 1\n","                    sequence.append(self.word_vocab[word])\n","                    target.append(self.target_vocab[label])\n","                    chars.append([self.char_vocab[char] for char in word])\n","            self.encoded_sequences.append(sequence)\n","            self.encoded_targets.append(target)\n","            self.encoded_char_sequences.append(chars)\n","\n","    def __len__(self):\n","        return len(self.encoded_sequences)\n","\n","    def __getitem__(self, index):\n","        return {\n","            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n","            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n","            'target': self.encoded_targets[index], # [1, 2, 3, 4, 6] len=5\n","        }"],"metadata":{"id":"SI8UCZuy7hTK","executionInfo":{"status":"ok","timestamp":1668446771269,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dataset = DatasetSeq(data_dir)"],"metadata":{"id":"dhJuBtoz7f43","executionInfo":{"status":"ok","timestamp":1668446776175,"user_tz":-180,"elapsed":2358,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#padding\n","# seq1 = [1, 2, 3, 4]\n","# seq2 = [9, 7, 6, 4, 3, 7, 5]\n","# pad seq1 equal seq2\n","# seq1 = [1, 2, 3, 4, 0, 0, 0]\n","# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n","#                     [9, 7, 6, 4, 3, 7, 5]]"],"metadata":{"id":"0zXXXYP37gFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    data = []\n","    target = []\n","    for item in batch:\n","        data.append(torch.as_tensor(item['data']))\n","        target.append(torch.as_tensor(item['target']))\n","    data = pad_sequence(data, batch_first=True, padding_value=0)\n","    target = pad_sequence(target, batch_first=True, padding_value=0)\n","\n","    return {'data': data, 'target': target}"],"metadata":{"id":"uPJauY4hAqJ6","executionInfo":{"status":"ok","timestamp":1668446778722,"user_tz":-180,"elapsed":3,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class RNNCell(nn.Module):\n","    def __init__(self, input_dim, hidden_dim):\n","        super().__init__()\n","        self.linear = nn.Linear(input_dim + hidden_dim, hidden_dim)\n","        self.activ = nn.Tanh()\n","\n","    def forward(self, x, h):\n","        x = torch.cat((x, h), dim=-1)\n","        x = self.linear(x)\n","        x = self.activ(x)\n","\n","        return x\n","\n","rnn_cell = RNNCell(64, 128)\n","seq = torch.tensor((6, 1, 64)) # T x B x Vdim\n","h = torch.zeros(1, 128)\n","\n","hiddens = []\n","for x in seq:\n","    h = rnn_cell(x, h)\n","    hiddens.append(h)\n"],"metadata":{"id":"AamT5mpsA1yZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ['cat', 'sat', 'on', 'mat']  len = 4\n","# encoded [23, 3, 323, 65]\n","# batch 1: [[23, 3, 323, 65]]   size=(1, 4) BxT\n","\n","\n","class RNNPredictor(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n","        super().__init__()\n","        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n","        self.rnn_cell = nn.GRUCell(emb_dim, hidden_dim)\n","        self.clf = nn.Linear(hidden_dim, n_classes)\n","        self.do = nn.Dropout(0.1)\n","        self.hidden_dim = hidden_dim\n","\n","    def forward(self, x): # B x T\n","        b, t  = x.size()\n","        emb = self.word_emb(x) # B x T x Emb_dim\n","        rnn_out = []\n","        hidden = torch.zeros(b, self.hidden_dim).to(x.device)\n","        for i in range(t):\n","            hidden = self.rnn_cell(emb[:, i, :], hidden)\n","            rnn_out.append(hidden.unsqueeze(1))\n","        rnn_out = torch.cat(rnn_out, dim=1) # B x T x Hid\n","        pred = self.clf(self.do(rnn_out)) # B x T x N_classes\n","\n","        return pred\n"],"metadata":{"id":"KTz2txO4LTZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNNPredictorV2(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n","        super().__init__()\n","        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n","        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n","        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","        self.clf = nn.Linear(hidden_dim, n_classes)\n","        self.do = nn.Dropout(0.1)\n","    \n","    def forward(self, x):\n","        emb = self.word_emb(x) # B x T x Emb_dim\n","        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n","        pred = self.clf(self.do(hidden)) # B x T x N_classes\n","\n","        return pred"],"metadata":{"id":"WBFZc1qY6HsC","executionInfo":{"status":"ok","timestamp":1668446785184,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#hyper params\n","vocab_size = len(dataset.word_vocab) + 1\n","n_classes = len(dataset.target_vocab) + 1\n","n_chars = len(dataset.char_vocab) + 1\n","#TODO try to use other model parameters\n","emb_dim = 256\n","hidden = 256\n","n_epochs = 10\n","batch_size = 64\n","cuda_device = 0\n","batch_size = 100\n","device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"],"metadata":{"id":"K_PACmDaH8Z7","executionInfo":{"status":"ok","timestamp":1668446787330,"user_tz":-180,"elapsed":2,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = RNNPredictorV2(vocab_size, emb_dim, hidden, n_classes).to(device)\n","model.train()\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.CrossEntropyLoss()"],"metadata":{"id":"a4gX5zVDIZdu","executionInfo":{"status":"ok","timestamp":1668446797116,"user_tz":-180,"elapsed":6551,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jVX0P0otIk4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9bMsBeqV8GCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for epoch in range(n_epochs):\n","    dataloader = DataLoader(dataset, \n","                            batch_size, \n","                            shuffle=True, \n","                            collate_fn=collate_fn,\n","                            drop_last = True,\n","                            )\n","    for i, batch in enumerate(dataloader):\n","        optim.zero_grad()\n","\n","        predict = model(batch['data'].to(device))\n","        loss = loss_func(predict.view(-1, n_classes),\n","                         batch['target'].to(device).view(-1), \n","                         )\n","        loss.backward()\n","        optim.step()\n","        if i % 100 == 0:\n","            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n","   \n","    torch.save(model.state_dict(), f'./rnn_chkpt_{epoch}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2f3MATJ8GKb","executionInfo":{"status":"ok","timestamp":1668446826614,"user_tz":-180,"elapsed":25742,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"8f4fd94f-ba07-4ad1-f800-c7330ab74ee9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0, step: 0, loss: 3.1588656902313232\n","epoch: 0, step: 100, loss: 0.34993281960487366\n","epoch: 0, step: 200, loss: 0.25862035155296326\n","epoch: 1, step: 0, loss: 0.1958320140838623\n","epoch: 1, step: 100, loss: 0.16330629587173462\n","epoch: 1, step: 200, loss: 0.12466469407081604\n","epoch: 2, step: 0, loss: 0.11442320793867111\n","epoch: 2, step: 100, loss: 0.13040633499622345\n","epoch: 2, step: 200, loss: 0.10265976190567017\n","epoch: 3, step: 0, loss: 0.0713106170296669\n","epoch: 3, step: 100, loss: 0.06167757138609886\n","epoch: 3, step: 200, loss: 0.07984483242034912\n","epoch: 4, step: 0, loss: 0.06311184167861938\n","epoch: 4, step: 100, loss: 0.06857133656740189\n","epoch: 4, step: 200, loss: 0.0752989649772644\n","epoch: 5, step: 0, loss: 0.059349142014980316\n","epoch: 5, step: 100, loss: 0.04456818103790283\n","epoch: 5, step: 200, loss: 0.07847759127616882\n","epoch: 6, step: 0, loss: 0.042301397770643234\n","epoch: 6, step: 100, loss: 0.04011691361665726\n","epoch: 6, step: 200, loss: 0.043618690222501755\n","epoch: 7, step: 0, loss: 0.04555872082710266\n","epoch: 7, step: 100, loss: 0.046829741448163986\n","epoch: 7, step: 200, loss: 0.03115173615515232\n","epoch: 8, step: 0, loss: 0.03383634611964226\n","epoch: 8, step: 100, loss: 0.03848479688167572\n","epoch: 8, step: 200, loss: 0.03330814465880394\n","epoch: 9, step: 0, loss: 0.02595282346010208\n","epoch: 9, step: 100, loss: 0.022537246346473694\n","epoch: 9, step: 200, loss: 0.031015193089842796\n"]}]},{"cell_type":"code","source":["\n","#example\n","phrase = 'He ran quickly after the red bus and caught it'\n","words = phrase.split(' ')\n","tokens = [dataset.word_vocab[w] for w in words]\n","\n","start = datetime.datetime.now()\n","with torch.no_grad():\n","    model.eval()\n","    predict = model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n","    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n","    end = datetime.datetime.now() - start\n","\n","target_labels = list(dataset.target_vocab.keys())\n","print([target_labels[l] for l in labels])"],"metadata":{"id":"9CljFAzIMMEW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447290860,"user_tz":-180,"elapsed":435,"user":{"displayName":"Boris Zhestkov","userId":"15589718157134474454"}},"outputId":"0d223b89-7e9f-4b4e-ab2c-fd5769eb1812"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"soes4kIU8FDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9PbgCjN48FRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"74gggSX58Fe9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-57Jq-CW8NmD"}}]}